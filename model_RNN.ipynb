{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm Detection RNN\n",
    "In this notebook, we'll implement a recurrent neural network that performs sarcasm detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')\n",
    "reviews = list(data['tweet'].apply(str))\n",
    "labels = list(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when father dysfunctional selfish drags kids into dysfunction #run', 'thanks #lyft credit cause they offer wheelchair vans #disapointed #getthanked', 'bihday your majesty', '#model love take with time', 'factsguide society #motivation', 'huge fare talking before they leave chaos disputes when they there #allshowandnogo', 'camping tomorrow danny', 'next school year year exams think about that #school #exams #hate #imagine #actorslife #revolutionschool #girl', 'love land #allin #cavs #champions #cleveland #clevelandcavaliers', 'welcome here']\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(reviews[:10])\n",
    "print()\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [word for sent in reviews for word in sent.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245274"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "## Build a dictionary \n",
    "counts = Counter(corpus)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_ints = []\n",
    "for review in reviews:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in review.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 31, 15657, 2976, 6080, 236, 159, 10008, 984]]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_ints[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(review_lens.keys(), review_lens.values())\n",
    "plt.title(\"Tweet length distribution\")\n",
    "plt.xlabel(\"Length\")\n",
    "plt.ylabel(\"Count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 20\n"
     ]
    }
   ],
   "source": [
    "review_lens = Counter([len(x) for x in reviews_ints])\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0   103 10009  2110   468    19\n",
      "  1298 10010 15658 15659 10011]\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation!\n",
    "\n",
    "seq_length = 17\n",
    "\n",
    "features = pad_features(reviews_ints, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 10 values of the first 30 batches \n",
    "print(features[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6394\n",
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(25570, 17) \n",
      "Validation set: \t(3195, 17) \n",
      "Test set: \t\t(3195, 17)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx+1], features[split_idx-1:]\n",
    "train_y, remaining_y = labels[:split_idx+1], labels[split_idx-1:]\n",
    "\n",
    "print(len(remaining_x))\n",
    "test_idx = int((len(remaining_x)-4)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx+4:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx+4:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(np.asarray(train_x)), torch.from_numpy(np.asarray(train_y)))\n",
    "valid_data = TensorDataset(torch.from_numpy(np.asarray(val_x)), torch.from_numpy(np.asarray(val_y)))\n",
    "test_data = TensorDataset(torch.from_numpy(np.asarray(test_x)), torch.from_numpy(np.asarray(test_y)))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 45\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([45, 17])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,     0,     0,     0,     0,     4,   197,     5,\n",
      "           423,    30,  7351, 25275,    29,  5922, 25276],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,  2268,  1873,    99,   248,   309],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0, 11102,    17,    66],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0, 30398, 30399,    54,   460, 30400],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,  1695,   649,   239,  1497,  1696],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,   108,   487,   597,\n",
      "         22816, 12646,   300,    41,   487, 22817,    72],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,   467,     8,    51,  1296,  1030,   447],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,   474,\n",
      "            64,    15,   706,   295,   375,  1001,   523],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "          2817,   177,    20,  5516, 28865,  1273, 28866],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,  3486,\n",
      "           692,  5064,    75,     6,   197,  4860, 28996],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,   623,\n",
      "            59,   162,    13, 19822,    22, 19823,  1971],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,  1889,   245,  1786],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,   260,\n",
      "            15,     5,     1,  9602,  4592,   118,  1338],\n",
      "        [    0,     0,     0,     0,     0,    40,   211,  2616,   161,   114,\n",
      "            21,   331,  2302,    71,    32,  7823,   353],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            93,   141,   113, 29532,  9737,  8151,  5880],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,  6892,  8647,  6892],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,  4184, 33749,  3122, 33750,  4458],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     1,   217,    96,\n",
      "          4861,   843,  9730, 33124, 33125,   890,     1],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "          2118,    22,  2102,  2742,     5, 27054,  5751],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,   179,   221,  2110,    10],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,  3387,  5405,\n",
      "          2438,  2010,  4662,    69,    90,    91,   111],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,    16, 16863,   253,\n",
      "           860, 16864,  3009, 16865,   757,   263,     7],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,   124,   783,  6860],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "          6811,  3693,  3110, 12135,   238,     7,   627],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,    32,   237,  7762, 32030, 32031, 32032],\n",
      "        [    0,     0,     0,     0,     0,   582,     4,  3506,     5,    56,\n",
      "           568,     3,   416,     3,  1034,   290, 22828],\n",
      "        [    0,     0,     0,  2302,   273,   267,   250,  2645,  1656,   926,\n",
      "          1008, 13644, 26490, 13645, 26491, 13646,  6698],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,   121,    99,   128,  3774],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,   789,    77,   311,\n",
      "           117,  2104,  1174,  2539,   754,  3960,  6858],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "         32535, 14828,  2111,  6615, 32536, 14927,  8058],\n",
      "        [    0,     0,     0,     0,     0,     0,  1431,   833,  1121,  2173,\n",
      "           397,  4811, 11394,  3476, 11395,  8456, 11396],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           178,   185,    49,    47,   208,   438,  5596],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,   464,\n",
      "           309,    92,    37,   100,    21,   758,    49],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     1,    12, 15084,    18],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     6,  1364,  8119,\n",
      "          8815, 21132,   808,  2164,   106, 21133,  3666],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           548,  1145,  3468,  4000,  4992, 14582, 14583],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            44,  1949,   937, 23929, 23930,   595,   388],\n",
      "        [    0,     0,     0,     0,     0,    57,     3,    54,   412,    28,\n",
      "          1505,  1612, 12018,  7157, 26694,     3,   142],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,    10,   930, 24750,     7,    29, 24751],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,   218,\n",
      "           464,   330, 23835,  7255,  2707,  1578,  9192],\n",
      "        [    0,     0,     0,     0,     0,     0,   135,  3025,  5191, 17693,\n",
      "          1403,  8156,  4687,  8157, 17694,    14,  6526],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,   630,   694,     6,\n",
      "          1412, 17361, 17362,   117, 17363,  3397,  1173],\n",
      "        [    0,     0,     0,     0,     0,   399,    10,  1638, 14777,     3,\n",
      "           421,   226,    62,   368,   278,  5989,  5996],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,    76,  1146, 11691,   482,   543],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           496,    87,   178,   265,   205,  9580,  1207]], dtype=torch.int32)\n",
      "\n",
      "Sample label size:  torch.Size([45])\n",
      "Sample label: \n",
      " tensor([0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(41709, 512)\n",
      "  (lstm): LSTM(512, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 1\n",
    "embedding_dim = 512\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "Epoch: 1/4... Step: 100... Loss: 0.253392... Val Loss: 0.675947\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "Epoch: 1/4... Step: 200... Loss: 0.253392... Val Loss: 0.675950\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 300... Loss: 0.253392... Val Loss: 0.675949\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n",
      "torch.Size([45, 17])\n",
      "torch.Size([45])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-09b255a38cd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                 \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m                 \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-124-7f6d5fe47b78>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, hidden)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0membeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mlstm_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# stack up lstm outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 559\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    560\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                print(inputs.shape)\n",
    "                print(labels.shape)\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output, h = net(inputs, h)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
