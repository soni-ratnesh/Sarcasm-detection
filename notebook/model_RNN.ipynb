{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm Detection RNN\n",
    "In this notebook, we'll implement a recurrent neural network that performs sarcasm detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_data.csv')\n",
    "reviews = list(data['tweet'].apply(str))\n",
    "labels = list(data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when father dysfunctional selfish drags kids into dysfunction #run', 'thanks #lyft credit cause they offer wheelchair vans #disapointed #getthanked', 'bihday your majesty', '#model love take with time', 'factsguide society #motivation', 'huge fare talking before they leave chaos disputes when they there #allshowandnogo', 'camping tomorrow danny', 'next school year year exams think about that #school #exams #hate #imagine #actorslife #revolutionschool #girl', 'love land #allin #cavs #champions #cleveland #clevelandcavaliers', 'welcome here']\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(reviews[:10])\n",
    "print()\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [word for sent in reviews for word in sent.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245274"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "## Build a dictionary \n",
    "counts = Counter(corpus)\n",
    "vocab = sorted(counts, key=counts.get, reverse=True)\n",
    "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_ints = []\n",
    "for review in reviews:\n",
    "    reviews_ints.append([vocab_to_int[word] for word in review.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10, 31, 15657, 2976, 6080, 236, 159, 10008, 984]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_ints[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum review length: 20\n"
     ]
    }
   ],
   "source": [
    "review_lens = Counter([len(x) for x in reviews_ints])\n",
    "print(\"Maximum review length: {}\".format(max(review_lens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(review_lens.keys(), review_lens.values())\n",
    "plt.title(\"Tweet length distribution\")\n",
    "plt.xlabel(\"Length\")\n",
    "plt.ylabel(\"Count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_features(reviews_ints, seq_length):\n",
    "    ''' Return features of review_ints, where each review is padded with 0's \n",
    "        or truncated to the input seq_length.\n",
    "    '''\n",
    "    \n",
    "    # getting the correct rows x cols shape\n",
    "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
    "\n",
    "    # for each review, I grab that review and \n",
    "    for i, row in enumerate(reviews_ints):\n",
    "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0     0     0     0     0     0   103 10009  2110   468    19\n",
      "  1298 10010 15658 15659 10011]\n"
     ]
    }
   ],
   "source": [
    "# Test your implementation!\n",
    "\n",
    "seq_length = 17\n",
    "\n",
    "features = pad_features(reviews_ints, seq_length=seq_length)\n",
    "\n",
    "## test statements - do not change - ##\n",
    "assert len(features)==len(reviews_ints), \"Your features should have as many rows as reviews.\"\n",
    "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
    "\n",
    "# print first 10 values of the first 30 batches \n",
    "print(features[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6394\n",
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t(25570, 17) \n",
      "Validation set: \t(3195, 17) \n",
      "Test set: \t\t(3195, 17)\n"
     ]
    }
   ],
   "source": [
    "split_frac = 0.8\n",
    "\n",
    "## split data into training, validation, and test data (features and labels, x and y)\n",
    "\n",
    "split_idx = int(len(features)*split_frac)\n",
    "train_x, remaining_x = features[:split_idx+1], features[split_idx-1:]\n",
    "train_y, remaining_y = labels[:split_idx+1], labels[split_idx-1:]\n",
    "\n",
    "print(len(remaining_x))\n",
    "test_idx = int((len(remaining_x)-4)*0.5)\n",
    "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx+4:]\n",
    "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx+4:]\n",
    "\n",
    "## print out the shapes of your resultant feature data\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
    "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
    "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(np.asarray(train_x)), torch.from_numpy(np.asarray(train_y)))\n",
    "valid_data = TensorDataset(torch.from_numpy(np.asarray(val_x)), torch.from_numpy(np.asarray(val_y)))\n",
    "test_data = TensorDataset(torch.from_numpy(np.asarray(test_x)), torch.from_numpy(np.asarray(test_y)))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 45\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size:  torch.Size([45, 17])\n",
      "Sample input: \n",
      " tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,   394,  2956, 13914],\n",
      "        [    0,     0,     0,   136,   118,    56,   390,     3,  1421,   306,\n",
      "             8,   345,   218,   156,   143,  2052,  1968],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,   236,     8,  5766,    31,    72],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,   167,  1231, 13697,    63,  3289],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,  1807,  1463,     4,\n",
      "           156,   628,  1663,  1521,  1402,    40,   405],\n",
      "        [    0,     0,     0,     0,     0,  3564,   206,    34,   145,    44,\n",
      "            57,     3,   289,   386,   166,   133,   299],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     6,\n",
      "            26,    40, 15067,    58,   101,   285,    29],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,    10,   143, 11792,\n",
      "            14,     4,    22,    15,  2183,   551,  2327],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0, 13734,   593,   565,  3891,   881,    41],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,   835,     2, 35815,\n",
      "             3,  2127,   267,   398,  2127,     3,  8617],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     6,   874,\n",
      "             2,   112,   104, 18011,   112,   874,   717],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,  9178,\n",
      "          3792,  5687,  1623,   585, 24222, 13073, 24223],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     6,  1412, 16574, 16575, 16576],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,   887, 36195, 36196, 36197],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,   359,   130],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             8,  1662,     4,  7163,    71,   121,   159],\n",
      "        [    0,     0,     0,     0,     0,     0,    89,    15,     1,    83,\n",
      "           545,    10,     9,    20,   542,  5077,  3062],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,   178,    81,\n",
      "            53,   431,  5979, 15126,  3646,  3646,  1990],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     9,    38,    76],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            20,    42,  1498, 11782,   267,   292,  1305],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,   228,    21,   229,   230,   229,   230],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,    44,    33,  1673,  9621,    51,   169],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "           623,    60,  5891,    63, 31176,    25,    95],\n",
      "        [    0,     0,     0,     0,     0,     0,  4612,  1227,  7969,  6373,\n",
      "          5331, 10557,   465, 10558, 10559,   773,   571],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,    12,    13,     9, 14467,   334],\n",
      "        [    0,     0,     0,     0, 35382,  2867,     8,   451,    23,  7797,\n",
      "           122,  1875,   300,    45,   115, 35383, 35384],\n",
      "        [    0,     0,     0,     0,     0,     0,     0, 29027,   149, 29028,\n",
      "         29029,  2770,   439, 29030,  5346,     7,   541],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,    40,  1000,   522,    27,   181,    94],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,   952,   310,\n",
      "         15899, 15900,  5152,  1804,   795,   164,  5153],\n",
      "        [    0,     0,     0,     0,     0, 14823,   206,    34,   709,    10,\n",
      "           255,   530,   412,     3,   257,   689,   259],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,    85,   174,\n",
      "           380,   262,   142,    88,   393,    80,   409],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0, 14905,     2, 14906,  1783,  5777,   972],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,    79,    32,\n",
      "         20540, 20541, 20542, 20543,   238, 20544, 20545],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0, 29763, 29764, 29765,   479],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,   985,  1215,   392,  1630,   750,  4013],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,    64],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,    26,  1189,\n",
      "         13421,   101, 28879,     7,   102,  5760, 28880],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     8,\n",
      "           204,  4302,   241, 13199,  3058,  1478,   451],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,  2830,  8059,  4650],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,   141,     5,    21,    76,   298, 28290],\n",
      "        [    0,     0,     0,     0,     0,     0, 22882,    20,  3936,   153,\n",
      "          1846,   784, 22883,   647,   143,   288,  7660],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,    10,    11,    65,\n",
      "            71,    10,     5,     2, 32373,  6541, 32374],\n",
      "        [    0,     0,     0,     0,     0,  2805,  9739,   484,   115,  2805,\n",
      "          9739,  1589, 29566,  6890,   467, 29567,  4316],\n",
      "        [    0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,   698, 13819, 13820, 13821],\n",
      "        [    0,     0,     0,     0,     0,     0,     0, 11225,   117,  2203,\n",
      "             2,     1,   324,    71, 21072, 21073, 21074]], dtype=torch.int32)\n",
      "\n",
      "Sample label size:  torch.Size([45])\n",
      "Sample label: \n",
      " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = dataiter.next()\n",
    "\n",
    "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print()\n",
    "print('Sample label size: ', sample_y.size()) # batch_size\n",
    "print('Sample label: \\n', sample_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# First checking if GPU is available\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentRNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The RNN model that will be used to perform Sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(SentimentRNN, self).__init__()\n",
    "\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        x = x.long()\n",
    "        embeds = self.embedding(x)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "    \n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        \n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "        \n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "        \n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "        \n",
    "        return hidden\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentRNN(\n",
      "  (embedding): Embedding(41709, 512)\n",
      "  (lstm): LSTM(512, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model w/ hyperparams\n",
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
    "output_size = 1\n",
    "embedding_dim = 512\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "\n",
    "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss and optimization functions\n",
    "lr=0.001\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/4... Step: 100... Loss: 0.240972... Val Loss: 0.202621\n",
      "Epoch: 2/4... Step: 200... Loss: 0.200948... Val Loss: 0.171935\n",
      "Epoch: 3/4... Step: 300... Loss: 0.036225... Val Loss: 0.156296\n",
      "Epoch: 4/4... Step: 400... Loss: 0.150362... Val Loss: 0.148040\n",
      "Epoch: 4/4... Step: 500... Loss: 0.173673... Val Loss: 0.137059\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "\n",
    "epochs = 4 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
    "\n",
    "counter = 0\n",
    "print_every = 100\n",
    "clip=5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "\n",
    "        if(train_on_gpu):\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero accumulated gradients\n",
    "        net.zero_grad()\n",
    "\n",
    "        # get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float())\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                if(train_on_gpu):\n",
    "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
    "#                 print(inputs.shape)\n",
    "#                 print(labels.shape)\n",
    "\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.167\n",
      "Test accuracy: 0.952\n"
     ]
    }
   ],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net.init_hidden(batch_size)\n",
    "\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "\n",
    "    # Creating new variables for the hidden state, otherwise\n",
    "    # we'd backprop through the entire training history\n",
    "    h = tuple([each.data for each in h])\n",
    "\n",
    "    if(train_on_gpu):\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    \n",
    "    # get predicted outputs\n",
    "    output, h = net(inputs, h)\n",
    "    \n",
    "    # calculate loss\n",
    "    test_loss = criterion(output.squeeze(), labels.float())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
