{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARCASM DETECTION EDA\n",
    "this module contain twitter exploratory data analysis for training thew model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "Import required lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required lib\n",
    "import re\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import string\n",
    "import nltk\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = pd.read_csv('data/train_E6oV3lV.csv')\n",
    "test = pd.read_csv('data/test_tweets_anuFYb8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset\n",
    "IN the pre-processing part we will be cleaning dataset for further use. The pipeline is as follows:<br>\n",
    "1. Reamoving @auther\n",
    "2. Remove words with lenth less than 3\n",
    "3. Removing Punctuations, Numbers, and Special Characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    \"\"\"\n",
    "    Remove given pattern form text\n",
    "    \"\"\"\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)\n",
    "        \n",
    "    return input_txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet'] = np.vectorize(remove_pattern)(train['tweet'], \"@[\\w]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet'] = train['tweet'].str.replace(\"[^a-zA-Z#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tweet'] = train['tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>when father dysfunctional selfish drags kids i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>thanks #lyft credit cause they offer wheelchai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model love take with time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  when father dysfunctional selfish drags kids i...\n",
       "1   2      0  thanks #lyft credit cause they offer wheelchai...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0                         #model love take with time\n",
       "4   5      0                     factsguide society #motivation"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview after cleanming\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "In this section data analysis is taken part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#model love take with time']\n"
     ]
    }
   ],
   "source": [
    "text=train['tweet'][3] #text for refernece\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "sents=sent_tokenize(text)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['#', 'model', 'love', 'take', 'with', 'time']]\n"
     ]
    }
   ],
   "source": [
    "#tokenize sentance by words \n",
    "words=[word_tokenize(sent) for sent in sents]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from string import punctuation\n",
    "customStopWords=set(stopwords.words('english')+list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model', 'love', 'take', 'time']\n"
     ]
    }
   ],
   "source": [
    "#Removing stopwords\n",
    "wordsWOStopwords=[word for word in word_tokenize(text) if word not in customStopWords]\n",
    "print(wordsWOStopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('love', 'take'), 1), (('model', 'love'), 1), (('take', 'time'), 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#taking bu-gram features\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "finder = BigramCollocationFinder.from_words(wordsWOStopwords)\n",
    "sorted(finder.ngram_fd.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#', 'model', 'lov', 'tak', 'with', 'tim']\n"
     ]
    }
   ],
   "source": [
    "#stemming words\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "st=LancasterStemmer()\n",
    "stemmedWords=[st.stem(word) for word in word_tokenize(text)]\n",
    "print(stemmedWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#', '#'),\n",
       " ('model', 'NN'),\n",
       " ('love', 'NNS'),\n",
       " ('take', 'VBP'),\n",
       " ('with', 'IN'),\n",
       " ('time', 'NN')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word tagging\n",
    "nltk.pos_tag(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('model.v.06') construct a model of\n"
     ]
    }
   ],
   "source": [
    "# Extact meaning of words\n",
    "from nltk.wsd import lesk\n",
    "sense1 = lesk(word_tokenize(text),'model')\n",
    "print(sense1, sense1.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Theory validation\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = train['tweet']\n",
    "labels = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reviews)):\n",
    "    if(labels[i] == 1):\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            positive_counts[word] += 1\n",
    "            total_counts[word] += 1\n",
    "    else:\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            negative_counts[word] += 1\n",
    "            total_counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 2875),\n",
       " ('with', 2635),\n",
       " ('that', 2266),\n",
       " ('your', 1779),\n",
       " ('have', 1745),\n",
       " ('happy', 1598),\n",
       " ('#love', 1552),\n",
       " ('just', 1440),\n",
       " ('will', 1346),\n",
       " ('when', 1309),\n",
       " ('what', 1269),\n",
       " ('love', 1236),\n",
       " ('like', 1169),\n",
       " ('from', 1131),\n",
       " ('time', 1124),\n",
       " ('today', 1033),\n",
       " ('about', 974),\n",
       " ('they', 937),\n",
       " ('people', 906),\n",
       " ('#positive', 878)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the counts of the most common words in positive reviews\n",
    "positive_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 5162),\n",
       " ('with', 4922),\n",
       " ('that', 3920),\n",
       " ('your', 3294),\n",
       " ('have', 3175),\n",
       " ('happy', 3163),\n",
       " ('#love', 3071),\n",
       " ('just', 2643),\n",
       " ('will', 2470),\n",
       " ('when', 2459),\n",
       " ('love', 2424),\n",
       " ('what', 2235),\n",
       " ('time', 2182),\n",
       " ('from', 2031),\n",
       " ('today', 2024),\n",
       " ('like', 1921),\n",
       " ('#positive', 1756),\n",
       " ('about', 1630),\n",
       " ('they', 1562),\n",
       " ('good', 1561)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the counts of the most common words in negative reviews\n",
    "negative_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter()\n",
    "\n",
    "# Calculate the ratios of positive and negative uses of the most common words\n",
    "\n",
    "for term,cnt in list(total_counts.most_common()):\n",
    "    if(cnt > 100):\n",
    "        pos_neg_ratio = positive_counts[term] / float(negative_counts[term]+1)\n",
    "        pos_neg_ratios[term] = pos_neg_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos-to-neg ratio for 'gorgeous' = 0.4927536231884058\n",
      "Pos-to-neg ratio for 'girls' = 0.6123188405797102\n",
      "Pos-to-neg ratio for 'racism' = 1.632183908045977\n"
     ]
    }
   ],
   "source": [
    "print(\"Pos-to-neg ratio for 'gorgeous' = {}\".format(pos_neg_ratios[\"gorgeous\"]))\n",
    "print(\"Pos-to-neg ratio for 'girls' = {}\".format(pos_neg_ratios[\"girls\"]))\n",
    "print(\"Pos-to-neg ratio for 'racism' = {}\".format(pos_neg_ratios[\"racism\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratios tell us which words are used more often in Sarcastic reviews, but the specific values we've calculated are a bit difficult to work with.<br>\n",
    "`To fix these issues, we'll convert all of our ratios to new values using logarithms.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word,ratio in pos_neg_ratios.most_common():\n",
    "    pos_neg_ratios[word] = np.log(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos-to-neg ratio for 'gorgeous' = -0.7077459799810979\n",
      "Pos-to-neg ratio for 'girls' = -0.49050215079407644\n",
      "Pos-to-neg ratio for 'racism' = 0.48991893894667704\n"
     ]
    }
   ],
   "source": [
    "print(\"Pos-to-neg ratio for 'gorgeous' = {}\".format(pos_neg_ratios[\"gorgeous\"]))\n",
    "print(\"Pos-to-neg ratio for 'girls' = {}\".format(pos_neg_ratios[\"girls\"]))\n",
    "print(\"Pos-to-neg ratio for 'racism' = {}\".format(pos_neg_ratios[\"racism\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#allahsoil', 0.6823362644557297),\n",
       " ('#sjw', 0.6797241602278047),\n",
       " ('#libtard', 0.660990068925414),\n",
       " ('libtard', 0.6405034470745233),\n",
       " ('#liberal', 0.6237186741281824),\n",
       " ('stomping', 0.6146755651184501),\n",
       " ('#politics', 0.6095604644516797),\n",
       " ('#tampa', 0.5787368293822011),\n",
       " ('racism', 0.48991893894667704),\n",
       " ('racist', 0.3214462520549885),\n",
       " ('#trump', 0.3011887712911459),\n",
       " ('#maga', 0.29334780998745824),\n",
       " ('#miami', 0.2525907526405108),\n",
       " ('#retweet', 0.24946085963158324),\n",
       " ('white', 0.23853470163450707),\n",
       " ('#obama', 0.1823215567939546),\n",
       " ('#black', 0.13846967426510512),\n",
       " ('comments', 0.09333193979221913),\n",
       " ('#hate', 0.08288765980576765),\n",
       " ('#brexit', 0.06899287148695142),\n",
       " ('anti', 0.018349138668196617),\n",
       " ('against', 0.005277057100843819),\n",
       " ('obama', -0.00722024797348702),\n",
       " ('listen', -0.011560822401075971),\n",
       " ('black', -0.0418179396833216),\n",
       " ('women', -0.04652001563489282),\n",
       " ('suppoers', -0.08594242980072477),\n",
       " ('woman', -0.1038995950181515),\n",
       " ('#leadership', -0.11934675763256625),\n",
       " ('latest', -0.13465688514625712)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_neg_ratios.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#workout', -0.7077459799810979),\n",
       " ('#fit', -0.7077459799810979),\n",
       " ('#chill', -0.7077459799810979),\n",
       " ('website', -0.7077459799810979),\n",
       " ('ness', -0.7077459799810979),\n",
       " ('#positivity', -0.7077459799810979),\n",
       " ('gorgeous', -0.7077459799810979),\n",
       " ('#essentialoils', -0.7077459799810979),\n",
       " ('planning', -0.7077459799810979),\n",
       " ('#sunset', -0.7077459799810979),\n",
       " ('yours', -0.7077459799810979),\n",
       " ('launch', -0.7077459799810979),\n",
       " ('dory', -0.7077459799810979),\n",
       " ('memories', -0.7077459799810979),\n",
       " ('#igers', -0.7077459799810979),\n",
       " ('#snapchat', -0.7077459799810979),\n",
       " ('florida', -0.7077459799810979),\n",
       " ('begins', -0.7077459799810979),\n",
       " ('feelings', -0.7077459799810979),\n",
       " ('christina', -0.7077459799810979),\n",
       " ('#run', -0.7077459799810979),\n",
       " ('august', -0.7073318155519017),\n",
       " ('#pray', -0.7073318155519017),\n",
       " ('broke', -0.7073318155519017),\n",
       " ('#heabroken', -0.7073318155519017),\n",
       " ('#behappy', -0.7073318155519017),\n",
       " ('#blogger', -0.7073318155519017),\n",
       " ('#youtube', -0.7073318155519017),\n",
       " ('#animals', -0.7073318155519017),\n",
       " ('lover', -0.7073318155519017)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(pos_neg_ratios.most_common()))[0:30]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "common words like \"the\" appear very often in both positive and negative reviews. Instead of finding the most common words in positive or negative reviews, what you really want are the words found in positive reviews more often than in negative reviews, and vice versa. To accomplish this, you'll need to calculate the **ratios** of word usage between positive and negative reviews."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
